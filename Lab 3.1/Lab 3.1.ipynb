{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13zI1UQuuS_F",
        "outputId": "23bd5b45-e7a7-418e-f922-a0af448a6fef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0: State = (0, 0), Action = 1.0\n",
            "Step 1: State = (1, 0), Action = 3.0\n",
            "Step 2: State = (1, 1), Action = 1.0\n",
            "Step 3: State = (2, 1), Action = 3.0\n",
            "Total reward obtained by learned policy: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        self.grid_size = (3, 3)\n",
        "        self.num_actions = 4  # Up, Down, Left, Right\n",
        "        self.start_state = (0, 0)\n",
        "        self.goal_state = (2, 2)\n",
        "\n",
        "    def step(self, state, action):\n",
        "        # Define the dynamics of the environment\n",
        "        row, col = state\n",
        "        if action == 0:  # Up\n",
        "            row = max(0, row - 1)\n",
        "        elif action == 1:  # Down\n",
        "            row = min(self.grid_size[0] - 1, row + 1)\n",
        "        elif action == 2:  # Left\n",
        "            col = max(0, col - 1)\n",
        "        elif action == 3:  # Right\n",
        "            col = min(self.grid_size[1] - 1, col + 1)\n",
        "        next_state = (row, col)\n",
        "        reward = 0\n",
        "        if next_state == self.goal_state:\n",
        "            reward = 1  # Reward of +1 upon reaching the goal state\n",
        "        return next_state, reward\n",
        "\n",
        "def generate_training_data(grid_world, num_samples):\n",
        "    X = np.zeros((num_samples, 2))  # State features\n",
        "    y = np.zeros((num_samples,))  # Actions\n",
        "    for i in range(num_samples):\n",
        "        state = (np.random.randint(grid_world.grid_size[0]),\n",
        "                 np.random.randint(grid_world.grid_size[1]))\n",
        "        action = np.random.randint(grid_world.num_actions)\n",
        "        next_state, _ = grid_world.step(state, action)\n",
        "        X[i] = state\n",
        "        y[i] = action\n",
        "    return X, y\n",
        "\n",
        "# Create a grid world environment\n",
        "grid_world = GridWorld()\n",
        "\n",
        "# Generate training data\n",
        "num_samples = 10000\n",
        "X_train, y_train = generate_training_data(grid_world, num_samples)\n",
        "\n",
        "# Train a supervised learning model using decision tree classifier\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the learned policy\n",
        "def evaluate_policy(grid_world, model):\n",
        "    total_reward = 0\n",
        "    state = grid_world.start_state\n",
        "    max_steps = 50\n",
        "    steps = 0\n",
        "    while state != grid_world.goal_state and steps < max_steps:\n",
        "        action = model.predict([state])[0]\n",
        "        print(f\"Step {steps}: State = {state}, Action = {action}\")\n",
        "        state, reward = grid_world.step(state, action)\n",
        "        total_reward += reward\n",
        "        steps += 1\n",
        "    return total_reward\n",
        "\n",
        "# Evaluate the learned policy\n",
        "total_reward = evaluate_policy(grid_world, model)\n",
        "print(\"Total reward obtained by learned policy:\", total_reward)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
