{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self):\n",
    "        self.grid_size = (3, 4)\n",
    "        self.num_actions = 4  # Up, Down, Left, Right\n",
    "        self.rewards = np.array([\n",
    "            [0, 0, 0, 0],\n",
    "            [0, 0, 0, 0],\n",
    "            [0, 0, 0, 1]  # Reward of +1 in the bottom-right cell\n",
    "        ])\n",
    "        self.start_state = (2, 0)\n",
    "\n",
    "    def step(self, state, action):\n",
    "        # Define the dynamics of the environment\n",
    "        row, col = state\n",
    "        if action == 0:  # Up\n",
    "            row = max(0, row - 1)\n",
    "        elif action == 1:  # Down\n",
    "            row = min(self.grid_size[0] - 1, row + 1)\n",
    "        elif action == 2:  # Left\n",
    "            col = max(0, col - 1)\n",
    "        elif action == 3:  # Right\n",
    "            col = min(self.grid_size[1] - 1, col + 1)\n",
    "\n",
    "        next_state = (row, col)\n",
    "        reward = self.rewards[row, col]\n",
    "        return next_state, reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated State-Value Function:\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def generate_episode(grid_world):\n",
    "    \"\"\"Generate a single episode using a random policy.\"\"\"\n",
    "    episode = []\n",
    "    state = grid_world.start_state\n",
    "\n",
    "    while state != (2, 3):  # Until reaching the bottom-right cell\n",
    "        action = np.random.choice(grid_world.num_actions)  # Random action\n",
    "        next_state, reward = grid_world.step(state, action)\n",
    "        episode.append((state, action, reward))\n",
    "        state = next_state\n",
    "\n",
    "    return episode\n",
    "\n",
    "def monte_carlo(grid_world, num_episodes, gamma=1.0):\n",
    "    \"\"\"Monte Carlo policy evaluation to estimate the state-value function.\"\"\"\n",
    "    V = np.zeros(grid_world.grid_size)  # Initialize state-value function\n",
    "    returns = {}  # Store returns for each state\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        episode_data = generate_episode(grid_world)\n",
    "        G = 0  # Initialize return\n",
    "\n",
    "        # Traverse the episode in reverse to calculate returns\n",
    "        for t in reversed(range(len(episode_data))):\n",
    "            state, _, reward = episode_data[t]\n",
    "            G = gamma * G + reward  # Discounted return\n",
    "\n",
    "            # Check if it's the first occurrence of the state in the episode\n",
    "            if state not in [(ep[0]) for ep in episode_data[:t]]:\n",
    "                if state not in returns:\n",
    "                    returns[state] = []\n",
    "                returns[state].append(G)\n",
    "                V[state] = np.mean(returns[state])  # Update state value\n",
    "\n",
    "    return V\n",
    "\n",
    "# Create a grid world environment\n",
    "grid_world = GridWorld()\n",
    "\n",
    "# Run Monte Carlo to estimate the state-value function\n",
    "num_episodes = 1000\n",
    "V = monte_carlo(grid_world, num_episodes)\n",
    "\n",
    "# Print the estimated state-value function\n",
    "print(\"Estimated State-Value Function:\")\n",
    "print(V)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
